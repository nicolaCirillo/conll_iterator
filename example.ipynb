{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conll_iterator import ConllIterator\n",
    "iterator = ConllIterator('sample/sample_corpus.conllu', ['form', 'upos'], mode='sentences', join_char='/')\n",
    "iterator.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage 1: Training word2vec with lemma+POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1807/1807 [00:00<00:00, 5863.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to Pecorino/PROPN:\n",
      "('Romano/PROPN', 'Spressa/PROPN', 'Chianti/PROPN', 'Classico/PROPN', 'Grana/PROPN', 'Giudicarie/PROPN', 'Padano/PROPN', 'Lenteja/PROPN', 'Queso/PROPN', 'Cappero/PROPN')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from conll_iterator import ConllIterator\n",
    "\n",
    "sentences = ConllIterator('sample/sample_corpus.conllu', fields=['lemma', 'upos'], mode='sentences', join_char='/')\n",
    "w2v_parameters = {'vector_size': 25, 'window': 5, 'min_count': 1, 'sg': 1, 'epochs': 15}\n",
    "model = Word2Vec(tqdm(sentences), workers=5, **w2v_parameters)\n",
    "model.save('sample/sample_w2v')\n",
    "word_vectors = model.wv\n",
    "similar = list(zip(*word_vectors.most_similar('Pecorino/PROPN')[:10]))[0]\n",
    "print(\"Most similar words to Pecorino/PROPN:\")\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage 2: Keyword extraction via tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords of doc 1: privativa; ritrovato; legittimazione; persona; assimilare; vegetale; giuridico; comunitario; valido; facilitare\n",
      "keywords of doc 2: albo; espressione; farmfresh; turkey; spagnolo; lingua; leche; granja; attestazione; serrano\n",
      "keywords of doc 3: reciproco; repubblica; romania; negoziato; protocollo; bulgaria; marocco; associazione; contingente; aspetto\n",
      "keywords of doc 4: gögginger; bier; cancellazione; cancellare; precedere; germania; denominazione; regolamento; richiesta; luce\n",
      "keywords of doc 5: valtellina; mela; denominazione; regolamento; marzo; italia; unione; europea; ce; numero\n",
      "keywords of doc 6: rogal; świętomarciński; polonia; regolamento; denominazione; ce; ottobre; numero; articolo; protetto\n",
      "keywords of doc 7: φάβα; σαντορίνης; fava; santorinis; grecia; denominazione; regolamento; dop; ottobre; unione\n",
      "keywords of doc 8: kalix; löjrom; svezia; denominazione; regolamento; novembre; dop; unione; europea; ce\n",
      "keywords of doc 9: coliflor; calahorra; ritirare; regolamento; denominazione; spagna; procedere; suddetto; ce; occorrere\n",
      "keywords of doc 10: pemento; oímbra; denominazione; regolamento; maggio; spagna; unione; europea; ce; numero\n",
      "keywords of doc 11: esaurire; effetto; raccolto; cee; speciale; adesione; riprendere; atto; divenire; tabacco\n",
      "keywords of doc 12: kiwi; adour; francia; regolamento; medesimo; denominazione; maggio; ce; numero; articolo\n",
      "keywords of doc 13: associazione; imprenditore; accertare; pratica; raggiungimento; corte; giustizia; commercio; concorrenza; impresa\n",
      "keywords of doc 14: ultraperiferiche; azzorre; posei; madera; zucchero; canarie; locale; approvvigionamento; tonnellata; dipartimento\n",
      "keywords of doc 15: sidra; asturias; asturies; completo; trattasi; cee; completare; regolamento; denominazione; iscrivere\n",
      "keywords of doc 16: pesca; noce; produttore; ritiro; promozionale; organizzazione; ortofrutticolo; supplementare; sostegno; aiuto\n",
      "keywords of doc 17: cornish; sardines; unito; regno; denominazione; regolamento; novembre; ce; numero; protetto\n",
      "keywords of doc 18: boerenkaas; p.; accogliere; protezione; attestazione; analogo; stg; bassi; alimentare; corrispondere\n",
      "keywords of doc 19: farro; monteleone; spoleto; denominazione; regolamento; luglio; italia; dop; unione; europea\n",
      "keywords of doc 20: grimsby; smoked; fish; traditional; unito; forza; regno; denominazione; regolamento; ce\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "docs = ConllIterator('sample/sample_corpus.conllu', fields=['lemma', 'upos'], lower=['lemma'], mode='documents')\n",
    "doc_tf = list()\n",
    "df = Counter()\n",
    "allowed_pos = ['NOUN', 'PROPN','VERB', 'ADJ']\n",
    "for d in docs:\n",
    "    tokens = list(chain(*d))\n",
    "    tokens = [t[0] for t in tokens if t[1] in allowed_pos]\n",
    "    tf = Counter(tokens)\n",
    "    df.update(set(tokens))\n",
    "    doc_tf.append(tf)\n",
    "\n",
    "doc_keywords = list()\n",
    "for d in doc_tf:\n",
    "    doc_tfidf = [(w, d[w]/df[w]) for w in d]\n",
    "    doc_tfidf = sorted(doc_tfidf, key=lambda x:x[1], reverse=True)\n",
    "    doc_keywords.append(list(zip(*doc_tfidf[:10]))[0])\n",
    "\n",
    "for i, k in enumerate(doc_keywords[:20]):\n",
    "    print('keywords of doc {}:'.format(i+1), '; '.join(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d762ffc7d2f958e0963c75da0d959adf181f4ac62524ed3e80179df28269f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
